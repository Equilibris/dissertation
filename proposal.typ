#import "@preview/fletcher:0.5.8" as fletcher: diagram, node, edge
#import "@preview/timeliney:0.4.0"
#import "@preview/wordometer:0.1.5": word-count, total-words

#import "template.typ": *
// Take a look at the file `template.typ` in the file panel
// to customise this template and discover how it works.
#show: common.with(
  title: "Diss",
  author: "William SÃ¸rensen",
  abstract: lorem(59),
  acknowledgements: lorem(59),
  date: "April 29, 2023",
  college: "Gonville & Caius College",
  logo: "cst_logo.svg"
)

#show: word-count

#emph(par(justify:false, text(40pt)[Efficent coinductives through state-machine corecursors]))

*Supervisor:* Alex Keizer

*Marking supervisor:* Tobias Grosser OR Jamie Vicary

*Word count:* #total-words

= Work to be undertaken

Previous work has shown how coinductives can be encoded in lean as quotients of polynomial functors (QPFs).
These are highly expressive but accessing cofixed points to a depth $n$ takes $cal(O)(n^2)$ time,
which compounds when you map data $m$ times to $cal(O)(n^2^m)$, this is a problem when using lean as a general purpose programming language.
Previous work has focused on trying to achieve this performance within the same universe.
An alternative approach is using the state-machine implementation of a corecursor.
This is a higher universe object which uses the corecursor directly.
// An alternative approach is trying rather to use Shrink which has the behaviour of allowing types in higher universes to be shrunk to the lower universes under certain circumstances.
Showing an equivalence between these two representations layes the groundwork for performance gains through future lean features.
// By showing an equivalence between the state-machine implementation of a cofixed point and the current implementation,
// we can instantiate Shrink.
With these we get nice computational behaviour,
meaning the entire expression collapses to $cal(O)(n)$.
A demonstration of the possible gains can be seen in @perf,
where the $x$-axis is the index into the array and the $y$-axis is a ns (scaled to 1e8) duration

#figure(
  image("MeanPerfWithSamples.png", width: 300pt),
  caption: [Graph plotting current performance v possible gains]
)<perf>

= Starting point

I have worked with QPFs on the meta-programming side for an internship between my Part Ia and Part Ib.
During this I learnt of the basics of polynomial functors, and TypeVecs.
This means I am aware of what the underlying structures are when it comes to the raw implementation.
I have also done a pheasability assessment of the project by seeing how the current polynomials respond to universe levels.
This lead to me making 2 pull requests (\#28095, \#28279) to mathlib on TypeVec in preparation for my project.
I also tried to pull requests (\#28112) an implementation of computable Shrink to mathlib that later got reverted when it was found to be absurd.

There are more minor refactoring pull requests towards the mathlib reposity which don't change any behaviour but in general all of these can be
#link("https://github.com/leanprover-community/mathlib4/issues?q=author%3AEquilibris%20created%3A%3C2025-10-10")[found on this link].
I Include these for completeness and transparency.

= Substance

There are a few structures that will be worked with during this project.

An attempt was made to make `Shrink` computable by using `unsafeCasts` but these had to be reverted.
For now the exact type is undecided as there is a RFC by the Lean FRO adding repr types for this purpose.

== `M`<mtype>

The `M` type is the name given to the terminal coalgebra of polynomial functors;
the possibly infinitely deep trees.
These are generated by progressive approximation where earlier trees must "agree" with the later ones.
Agreement is given by them being the same up to the previous depth.
A visual example is given in @agree.
We can have approximations for any n,
thereby letting the trees take any depth including infinite depth.
Trees can be terminated by having no children as one might expect.

#figure(
  diagram(cell-size:5mm, $
  0 edge("rrrrrrrrr", "..") & & & edge("lld") edge("d") edge("dr") & & & & edge("lld") edge("dd") edge("dr") &
  \
  1 edge("rrrrrrrrr", "..") & & & & & edge("d") edge("dr") & & & edge("d")
  \
  2 edge("rrrrrrrrr", "..")
  $),
  caption:[Agreement of two trees of height 1 and 2]
)<agree>

The current QPF implementation has 2 `M` types;
univariate and multivariate implementations.
These both have the undesired computational behaviour.
`M` types are polynomial

== `Cofix`<cfix>

`Cofix` is the terminal coalgebra in QPFs,
(possibly) infinitely big quotiented trees.
This is the slightly concerning part of the project and by far the highest risk section as working with `Quot` in Lean is a painful experience.

== `Shrink`<shrk>

`Shrink` is temporarily the choice used for doing the ABI translation between the two implementations.
Given that the two types are equivalent then we can non-computably extract a model in the desired universe.
Given two types $alpha : "Type" u$ and $beta : "Type" v$ for which an isomorphism exists,
we can construct the type $"Shrink" alpha beta : "Type" v$ for which both diagrams in @shrkops commute.

#figure(
  diagram(cell-size: 15mm, $
      alpha
        edge("m" "k", ->)
        edge("dr", bb(1)_alpha, ->)
      & "Shrink" alpha beta
        edge("d", "d" "e" "s" "t", ->, label-side: #left)
      & "Shrink" alpha beta
        edge("d", "d" "e" "s" "t", ->, label-side: #left)
        edge("dr", bb(1)_("Shrink" alpha beta), ->)
      \
      & alpha
      & alpha
        edge("m" "k", ->)
      & "Shrink" alpha beta
  $),
  caption:[Operations on Shrink]
)<shrkops>


= Evaluation

The success of this project can be given by how close to the theorised performance we can get to.
The goal would be getting to the same order or magnitude.

= Core timeline

#timeliney.timeline(
  show-grid: true,
  {
    import timeliney: *

    headerline(
      group(([*Oct 25*], 4)),
      group(([*Nov 25*], 4)),
      group(([*Dec 25*], 4)),
      group(([*Jan 26*], 4)),
      group(([*Feb 26*], 4)),
      group(([*Mar 26*], 4))
    )

    headerline(
      ([11], 1), ([18], 1), ([25], 1),
      ([1],  1), ([8],  1), ([15], 1), ([22], 1),
      ([29], 1), ([6],  1), ([13], 1), ([20], 1),
      ([27], 1), ([3],  1), ([10], 1), ([17], 1),
      ([24], 1), ([31], 1), ([7],  1), ([14], 1),
      ([21], 1), ([28], 1), ([7],  1), ([14], 1)
    )

    taskgroup(
      title: [*Core Work*],
      {
        task("Variable universe M's", (from: 0, to: 2, style: (stroke: blue)))
        task("List special example", (from: 2, to: 4, style: (stroke: green)))
        task("Univariate M", (from: 4, to: 9, style: (stroke: orange)))
        task("Multivariate M", (from: 9, to: 13, style: (stroke: red)))
        task("Cofix", (from: 13, to: 19, style: (stroke: purple)))
      }
    )

    taskgroup(
      title: [*Extensions*],
      {
        task("Fast Precoroutines", (from: 19, to: 21, style: (stroke: gray)))
        task("Fast Precoroutines", (from: 21, to: 23, style: (stroke: gray)))
      }
    )

    milestone(
      at: 7,
      align(center, [
        *CAT Exam*\
        Dec 2025
      ])
    )
  }
)

The plan for work would be divided into a few different stages.

== Variable universe `M`s (2025-10-11 2w 2025-10-24)

To begin, the pull requests created from before the start of the project will have to be completed and merged into `mathlib`.

== `List` special example (2025-10-25 2w 2025-11-7)

An early step would be to familiarise myself with using the bisimilarity features given by the `M` type.
This asses pheasability to prove equivalences of two `M` types with a simple functor.

== Univariate `M` (2025-11-8 2w 2025-11-21 + (CAT exam) + 2025-12-05 3w 2025-12-23)

After a special example I would move over to the univariate example.
This will be much easier than the multivariate case as I don't have to suffer with `Typevec`s.

== Multivariate `M` (2025-12-26 4w 2026-01-23)

This will be the next natural step.
Will me much harder than the univariate.

== `Cofix` (2026-01-24 6w 2026-03-06)

Finally, it has to be proven for `Cofix`.
This will be hard as I will have to suffer with Quot which is really concerning to work with.

= Extensions

== `Shrink`ing the representations (2026-03-07 2w 2026-03-20)

This is a research heavy component of the project.
This involves finding a sound way of implementing @shrk.
This will be novel work.

== A fast implementation of `Precoroutines` (2026-03-21 2w 2026-04-04)

Precoroutines are a type Alex Keizer is interested in.
They generalise interaction trees and other similar data-types useful for denotational purposes.
These leverage some of the powers of QPFs.
This should come for free from the prior the core.

= Resources

Access to the restricted side of the lab is needed for working with the further team.

